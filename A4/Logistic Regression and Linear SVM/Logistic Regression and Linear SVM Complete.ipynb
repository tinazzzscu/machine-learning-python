{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will draw couple of plots during the lecture. We activate matplotlib to show the plots inline in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides state-of-the-art machine learning algorithms. \n",
    "These algorithms, however, cannot be directly used on raw data. Raw data needs to be preprocessed beforehand. Thus, besides machine learning algorithms, `scikit-learn` provides a set of preprocessing methods. Furthermore, `scikit-learn` provides connectors for pipelining these estimators (i.e., transformer, regressor, classifier, clusterer, etc.).\n",
    "\n",
    "In this lecture, we will present the set of `scikit-learn` functionalities allowing for pipelining estimators, evaluating those pipelines, tuning those pipelines using hyper-parameters optimization, and creating complex preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic use-case: train and test a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first example, we will train and test a classifier on a dataset. We will use this example to recall the API of `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `digits` dataset which is a dataset of hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X` contains the intensities of the 64 image pixels. For each sample in `X`, we get the ground-truth `y` indicating the digit written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit in the image is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAA/5JREFUeJzt3cFRomkUhtGPqU6AFDAETAVC0BA0BHMhBAlBUjAECYFJwFlMld5unz5nyYLXAp76q9zcze12W0DHP7/7DwC+lqghRtQQI2qIETXE/PqON91sNsl/qR8Oh9G9l5eXsa3z+Ty29fz8PLZ1vV7HtqbdbrfNZ697UkOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCHmW87uVE2ewVlrrd1uN7a13W7Htj4+Psa2jsfj2NZaa51Op9G9z3hSQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIebHn93Z7/djW5NncNZa6+7ubmzr/f19bOv19XVsa/L3sZazO8A3EDXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpifvwtre12O7Z1uVzGttaavW81afpz/Nt4UkOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCHG2Z3/4Xw+j22VTX5n1+t1bOtP4UkNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGmB9/dmfyrMp+vx/bmjZ5CmfyczydTmNbfwpPaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcRsbrfb17/pZvP1b/ofdrvd1NR6e3sb21prrcfHx7Gtw+EwtjX5nd3f349tTbvdbpvPXvekhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIebH39Ka9PDwMLr39PQ0tnW5XMa2jsfj2FaZW1rwlxA1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xHzL2R3g9/GkhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmL+BXOCUu0hYKBYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(8, 8), cmap='gray');\n",
    "plt.axis('off')\n",
    "print('The digit in the image is {}'.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we should evaluate our model by training and testing it on distinct sets of data. `train_test_split` is a utility function to split the data into two independent sets. The `stratify` parameter enforces the classes distribution of the train and test datasets to be the same than the one of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have independent training and testing sets, we can learn a machine learning model using the `fit` method. We will use the `score` method to test this method, relying on the default accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', C=1.0, multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization strength increases in $\\lambda$\n",
    "\n",
    "slides: $\\lambda$\n",
    "\n",
    "sklearn:\n",
    "\n",
    "regression: $\\alpha = \\lambda$\n",
    "\n",
    "classification: $C = 1/\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -6.30384001e-03,  2.96004510e-02,  3.88698761e-02,\n",
       "        2.65804007e-02, -6.67178917e-02, -1.31979140e-01, -1.82135723e-02,\n",
       "       -1.15099549e-05, -5.44233636e-02,  3.44053170e-02,  1.81021013e-01,\n",
       "        1.13009846e-02,  6.40923453e-02, -4.69913462e-02, -1.90296785e-02,\n",
       "        9.94271130e-08,  2.83640922e-02,  9.38930527e-02, -5.30103048e-02,\n",
       "       -2.75673390e-01,  4.64541332e-02,  6.24008434e-02, -5.61503459e-03,\n",
       "        4.72715679e-08,  1.24948338e-01,  1.17692512e-01, -1.24176789e-01,\n",
       "       -3.84945462e-01, -1.70700510e-02,  1.07098208e-01, -3.65307049e-05,\n",
       "        0.00000000e+00,  1.70830405e-01,  4.72732710e-02, -1.66551086e-01,\n",
       "       -3.25627688e-01,  7.89617891e-02,  6.21531889e-02,  0.00000000e+00,\n",
       "       -5.88857709e-05,  7.04062544e-03,  1.74078556e-01, -7.00565956e-02,\n",
       "       -1.48926938e-01,  1.14179999e-01,  1.07252007e-02, -6.40960559e-06,\n",
       "       -2.27199611e-04, -6.42472467e-02,  8.46581908e-02, -4.98843857e-02,\n",
       "        1.54396280e-01,  1.51476660e-02, -2.92896631e-03, -1.46347955e-03,\n",
       "        4.88811891e-08, -2.46859478e-03, -1.03652386e-02,  1.04643941e-01,\n",
       "       -5.51373523e-02, -1.51218900e-02, -4.29083262e-02, -6.83342033e-03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.8870991 , -10.08535304,   2.26720202,  -3.82055539,\n",
       "        16.13729243,  -4.84851607,   1.55615451,   8.99747188,\n",
       "        -0.95250658, -11.13828885])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API of `scikit-learn` is consistent across classifiers. Thus, we can easily replace the `LogisticRegression` classifier by a `LinearSVC Classifier`. These changes are minimal and only related to the creation of the classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LinearSVC is 0.942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(C=1.0, max_iter=500000)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More advanced use-case: preprocess the data before training and testing a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standardize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing might be required before learning a model. For instance, a user could be interested in creating hand-crafted features or an algorithm might make some apriori assumptions about the data. \n",
    "\n",
    "In our case, the solver used by the `LogisticRegression` expects the data to be normalized. Thus, we need to standardize the data before training the model. To observe this necessary condition, we will check the number of iterations required to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.953\n",
      "LogisticRegression required 2314 iterations to be fitted\n",
      "Accuracy score of the LinearSVC is 0.942\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "accuracy = clf1.score(X_test, y_test)\n",
    "\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf1.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf1.__class__.__name__, clf1.n_iter_[0]))\n",
    "\n",
    "clf2 = LinearSVC(max_iter=500000)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "accuracy = clf2.score(X_test, y_test)\n",
    "\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf2.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.962\n",
      "LogisticRegression required 192 iterations to be fitted\n",
      "Accuracy score of the LinearSVC is 0.969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# X_train_scaled = scaler.fit(X_train) #find min and max of each feature in the training set\n",
    "\n",
    "# X_train_scaled = scaler.transform(X_train) #normalize the training set (using the min and max found above)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test) #normalize the testing set (using the min and max found above)\n",
    "\n",
    "clf1.fit(X_train_scaled, y_train)\n",
    "accuracy = clf1.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf1.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf1.__class__.__name__, clf1.n_iter_[0]))\n",
    "\n",
    "clf2.fit(X_train_scaled, y_train)\n",
    "accuracy = clf2.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf2.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.978\n",
      "LogisticRegression required 89 iterations to be fitted\n",
      "Accuracy score of the LinearSVC is 0.951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf1.fit(X_train_scaled, y_train)\n",
    "accuracy = clf1.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf1.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf1.__class__.__name__, clf1.n_iter_[0]))\n",
    "\n",
    "clf2.fit(X_train_scaled, y_train)\n",
    "accuracy = clf2.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf2.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MinMaxScaler` and `StandardScaler` transformers are used to normalise the data. Other scalers include `RobustScaler` and `Normalizer`. The scaler should be applied in the following way: learn (i.e., `fit` method) the statistics on a training set and standardize (i.e., `transform` method) both the training and testing sets. Finally, we will train and test the model and the scaled datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By scaling the data, the convergence of the model happened much faster than with the unscaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any feature: \n",
    "\n",
    "MinMaxScaler: (x-min)/(max-min)\n",
    "\n",
    "StandardScaler: (x-mean)/standard deviation;\n",
    "\n",
    "RobustScaler: (x-median)/(75% quantile - 25% quantile)\n",
    "\n",
    "for any observation:\n",
    "Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/scaler_comparison_scatter.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The wrong preprocessing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We highlighted how to preprocess and adequately train a machine learning model. It is also interesting to spot what would be the wrong way of preprocessing data. There are two potential mistakes which are easy to make but easy to spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pattern is to standardize the data before spliting the full set into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.962\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_prescaled, X_test_prescaled, y_train_prescaled, y_test_prescaled = train_test_split(\n",
    "    X_scaled, y, stratify=y, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train_prescaled)\n",
    "accuracy = clf.score(X_test_prescaled, y_test_prescaled)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second pattern is to standardize the training and testing sets independently. It comes back to call the `fit` methods on both training and testing sets. Thus, the training and testing sets are standardized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.962\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_prescaled = scaler.fit_transform(X_train)\n",
    "X_test_prescaled = scaler.fit_transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train)\n",
    "accuracy = clf.score(X_test_prescaled, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/no_separate_scaling.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Keep it simple, stupid: use the pipeline connector from `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two previous patterns are an issue with data leaking. However, this is difficult to prevent such a mistake when one has to do the preprocessing by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, `scikit-learn` introduced the `Pipeline` object. It sequentially connects several transformers and a classifier (or a regressor). We can create a pipeline as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                       ('clf', LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this pipeline contains the parameters of both the scaler and the classifier. The general pipeline can join any number of estimators together. For example, you could build a pipeline containing feature extraction, feature selection, scaling, and classification, for a total of four steps. Similarly, the last step could be regression or clustering instead of classification. \n",
    "\n",
    "Sometimes, it can be tedious to give a name to each estimator in the pipeline. `make_pipeline` will give a name automatically to each estimator which is the lower case of the class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42, max_iter=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will have an identical API. We use `fit` to train the classifier and `score` to check the accuracy. However, calling `fit` will call the method `fit_transform` of all transformers in the pipeline. Calling `score` (or `predict` and `predict_proba`) will call internally `transform` of all transformers in the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.962\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check all the parameters of the pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
       "             n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'minmaxscaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
       "           n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 1000,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides three functions: `cross_val_score`, `cross_val_predict`, and [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html). The latter provides more information regarding fitting time, training and testing scores. I can also return multiple scores at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto',\n",
    "                                        max_iter=1000, random_state=42))\n",
    "scores = cross_validate(pipe, X, y, cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cross-validate function, we can quickly check the training and testing scores and make a quick plot using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.140623</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.925249</td>\n",
       "      <td>0.988285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943239</td>\n",
       "      <td>0.984975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924497</td>\n",
       "      <td>0.993339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.140623    0.000998    0.925249     0.988285\n",
       "1  0.106717    0.000000    0.943239     0.984975\n",
       "2  0.111698    0.000000    0.924497     0.993339"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean times and scores:\n",
      " fit_time       0.119679\n",
      "score_time     0.000333\n",
      "test_score     0.930995\n",
      "train_score    0.988866\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean times and scores:\\n\", df_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c587797be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper-parameters optimization: fine-tune the inside of a pipeline using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you would like to find the parameters of a component of the pipeline which lead to the best accuracy. We already saw that we could check the parameters of a pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
       "             n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'minmaxscaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
       "           n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 1000,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters can be optimized by an exhaustive search. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) provides such utility and does a cross-validated grid-search over a parameter grid.\n",
    "\n",
    "Let's give an example in which we would like to optimize the `C` and `penalty` parameters of the `LogisticRegression` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=5000, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'logisticregression__C': [0.1, 1.0, 10], 'logisticregression__penalty': ['l2', 'l1']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto',\n",
    "                                        random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the grid-search object, it finds the best possible parameter combination on the training set (using cross-validation). We can introspect the results of the grid-search by accessing the attribute `cv_results_`. It allows us to check the effect of the parameters on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283754</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>2.008389e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.951542</td>\n",
       "      <td>0.935268</td>\n",
       "      <td>0.941573</td>\n",
       "      <td>0.942836</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>5</td>\n",
       "      <td>0.952968</td>\n",
       "      <td>0.959956</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>0.955084</td>\n",
       "      <td>0.003455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.173824</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>1.695451e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.885463</td>\n",
       "      <td>0.908482</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.892353</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905935</td>\n",
       "      <td>0.902113</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.903496</td>\n",
       "      <td>0.001730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952433</td>\n",
       "      <td>0.017516</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.963623</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985442</td>\n",
       "      <td>0.987764</td>\n",
       "      <td>0.986696</td>\n",
       "      <td>0.986634</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.679312</td>\n",
       "      <td>1.044898</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.704712e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>0.950893</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.953229</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977604</td>\n",
       "      <td>0.977753</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>0.978837</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.514586</td>\n",
       "      <td>0.263775</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>5.947204e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.962054</td>\n",
       "      <td>0.964045</td>\n",
       "      <td>0.968077</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.216869</td>\n",
       "      <td>1.238863</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>4.705279e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.957589</td>\n",
       "      <td>0.950562</td>\n",
       "      <td>0.960653</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.283754      0.013802         0.005422    2.008389e-03   \n",
       "1       0.750687      0.173824         0.001663    1.695451e-03   \n",
       "2       0.952433      0.017516         0.000998    1.946680e-07   \n",
       "3       3.679312      1.044898         0.000333    4.704712e-04   \n",
       "4       2.514586      0.263775         0.000998    5.947204e-07   \n",
       "5       9.216869      1.238863         0.000665    4.705279e-04   \n",
       "\n",
       "  param_logisticregression__C param_logisticregression__penalty  \\\n",
       "0                         0.1                                l2   \n",
       "1                         0.1                                l1   \n",
       "2                           1                                l2   \n",
       "3                           1                                l1   \n",
       "4                          10                                l2   \n",
       "5                          10                                l1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'logisticregression__C': 0.1, 'logisticregres...           0.951542   \n",
       "1  {'logisticregression__C': 0.1, 'logisticregres...           0.885463   \n",
       "2  {'logisticregression__C': 1.0, 'logisticregres...           0.977974   \n",
       "3  {'logisticregression__C': 1.0, 'logisticregres...           0.964758   \n",
       "4  {'logisticregression__C': 10, 'logisticregress...           0.977974   \n",
       "5  {'logisticregression__C': 10, 'logisticregress...           0.973568   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.935268           0.941573         0.942836        0.006717   \n",
       "1           0.908482           0.883146         0.892353        0.011425   \n",
       "2           0.955357           0.957303         0.963623        0.010263   \n",
       "3           0.950893           0.943820         0.953229        0.008710   \n",
       "4           0.962054           0.964045         0.968077        0.007103   \n",
       "5           0.957589           0.950562         0.960653        0.009643   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            0.952968            0.959956   \n",
       "1                6            0.905935            0.902113   \n",
       "2                2            0.985442            0.987764   \n",
       "3                4            0.977604            0.977753   \n",
       "4                1            1.000000            1.000000   \n",
       "5                3            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.952328          0.955084         0.003455  \n",
       "1            0.902439          0.903496         0.001730  \n",
       "2            0.986696          0.986634         0.000949  \n",
       "3            0.981153          0.978837         0.001639  \n",
       "4            1.000000          1.000000         0.000000  \n",
       "5            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_)\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': [0.1, 1.0, 10],\n",
       " 'logisticregression__penalty': ['l2', 'l1']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.pivot_table(pd.DataFrame(grid.cv_results_), values='mean_test_score', index='param_logisticregression__C', columns='param_logisticregression__penalty')\n",
    "pd.set_option(\"display.precision\",3)\n",
    "res = res.set_index(res.index.values.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "param_logisticregression__penalty     l1     l2\n",
       "0.1                                0.892  0.943\n",
       "1.0                                0.953  0.964\n",
       "10.0                               0.961  0.968"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c587a47898>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(res, annot=True, fmt=\".3g\", vmin=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the grid-search object is also behaving as an estimator. Once it is fitted, calling `score` will fix the hyper-parameters to the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10, 'logisticregression__penalty': 'l2'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "Pipeline(memory=None,\n",
      "     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('logisticregression', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=5000, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator:\\n{}\".format(grid.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression step:\n",
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=5000, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='saga',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression step:\\n{}\".format(\n",
    "      grid.best_estimator_.named_steps[\"logisticregression\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression coefficients:\n",
      "[[ 0.00000000e+00 -1.03876781e-01  9.78175742e-02  6.75104096e-01\n",
      "   1.67449815e-01 -8.91859368e-01 -9.26870306e-01 -1.19321074e-01\n",
      "  -3.68210118e-03 -4.19285459e-01  2.20611842e-01  1.16619671e+00\n",
      "   4.00501029e-01  7.95458012e-01 -3.41012961e-01 -1.47979881e-01\n",
      "  -5.83333273e-06  2.54594401e-01  9.95136382e-01 -4.80175165e-01\n",
      "  -2.19413919e+00  7.85849291e-01  6.03428944e-01 -6.20527350e-02\n",
      "  -5.18594197e-05  1.00543208e+00  1.01228546e+00 -1.16056001e+00\n",
      "  -3.54449354e+00 -1.76728639e-01  1.02753233e+00 -2.66715641e-02\n",
      "   0.00000000e+00  1.50415368e+00  5.88047094e-01 -1.56131655e+00\n",
      "  -2.89806723e+00  3.92655496e-01  7.57661638e-01  0.00000000e+00\n",
      "  -2.68750940e-02  1.01450546e-01  1.65605414e+00 -6.95809252e-01\n",
      "  -1.48416258e+00  8.59487888e-01  3.06213457e-01 -1.40978545e-03\n",
      "  -2.33547147e-02 -5.19665898e-01  7.76694168e-01 -1.88331455e-01\n",
      "   1.00322504e+00  3.70643455e-01 -3.02266038e-01 -3.21687309e-02\n",
      "  -1.61512205e-04 -2.39730524e-02 -1.35409509e-01  8.05202840e-01\n",
      "  -3.39673141e-01 -3.22124584e-01 -5.14446134e-01 -1.04664329e-01]\n",
      " [ 0.00000000e+00 -3.70048795e-02 -2.05991206e-01  8.95989420e-01\n",
      "  -3.76944417e+00  1.83141282e+00  2.96294250e-01 -3.70611650e-02\n",
      "  -1.16166614e-01 -2.42776472e+00 -3.26932681e+00 -8.50610588e-01\n",
      "   8.82638681e-01  1.12271261e+00 -2.02780513e+00 -2.02171641e-02\n",
      "  -1.04428065e-03  9.25474851e-01 -1.21033948e-01  4.39842632e+00\n",
      "   4.04829007e+00 -5.06350439e-01 -1.01422801e-01 -2.20947825e-02\n",
      "  -3.11649700e-01 -4.98208735e-01  8.76759052e-01  1.72751180e+00\n",
      "   9.53999084e-01  4.75914573e-01  5.50584136e-02 -1.45595627e-03\n",
      "   0.00000000e+00  2.93060263e-01  7.86741438e-01 -7.04988923e-01\n",
      "   6.68214360e-01  5.41060081e-01 -9.13780570e-01  0.00000000e+00\n",
      "  -4.44240403e-03 -1.34613191e+00  1.60078549e-01  1.28130333e+00\n",
      "   1.25769010e+00 -1.49894722e+00 -2.18625454e+00 -3.20253025e-02\n",
      "  -6.04963251e-03 -1.06762323e+00 -1.04544010e+00  1.07010512e+00\n",
      "   2.21627448e+00 -7.10804230e-01 -7.05997590e-01  1.35685126e+00\n",
      "  -1.56513331e-02  3.84787367e-02 -1.38508394e+00 -1.61373245e-01\n",
      "   3.61139230e-01  1.81827801e+00  1.99810027e+00  1.80573540e+00]\n",
      " [ 0.00000000e+00  2.55328808e-01  3.29436713e-01  4.42730278e-01\n",
      "   4.09959509e-01 -2.26342092e-01 -2.18145384e-01 -6.54273017e-03\n",
      "  -2.56203518e-02  1.86901784e+00  2.23627564e-01 -1.26643726e+00\n",
      "   1.51293062e+00  1.60079710e-01 -5.52245006e-02 -2.02952332e-02\n",
      "   1.54694451e-01 -1.35613989e-01 -8.83443566e-01 -1.53954839e+00\n",
      "   1.52942095e+00 -3.65858784e-01  1.05922642e+00 -3.05566709e-04\n",
      "  -1.04151136e-05 -1.07067309e+00 -3.77202583e+00 -3.30544824e+00\n",
      "  -1.78775194e+00  5.68392544e-02  2.64043639e-01 -1.04201066e-04\n",
      "   0.00000000e+00 -1.11125791e+00 -2.47049315e+00 -8.11440900e-01\n",
      "  -6.20663727e-02 -1.56353795e+00 -1.66238287e+00  0.00000000e+00\n",
      "  -7.53996292e-05  7.15167493e-01  3.62192449e-01  3.07771423e+00\n",
      "  -2.17805217e+00 -2.38387412e+00 -1.20292899e+00  1.18405509e-01\n",
      "   4.37023773e-02  7.70018349e-01  5.50961717e-01  3.59354837e+00\n",
      "   2.36276396e+00  2.65757174e+00  1.01665020e+00  4.82477054e-01\n",
      "   1.16721633e-01  4.28495857e-01  1.17673513e+00  6.71745032e-01\n",
      "   2.02310371e-01  1.78634915e+00  2.42394027e+00  9.30938046e-01]\n",
      " [ 0.00000000e+00  1.14587543e+00 -8.80408398e-01  5.77641319e-01\n",
      "   3.23390278e+00  1.21621320e+00  1.37603671e-03 -3.44414273e-03\n",
      "  -9.49505967e-02  7.74224597e-01  1.04204875e+00  3.93038567e-01\n",
      "   1.35494200e+00  9.51762509e-01  1.35103955e+00 -1.76080234e-01\n",
      "  -1.44230586e-01 -3.74993595e-01 -2.73016620e+00 -3.26641625e+00\n",
      "   5.57624732e-01 -1.34626372e+00  9.56213839e-02 -2.17344911e-02\n",
      "  -7.23120444e-06 -1.22909503e+00 -3.35608884e+00 -9.79612560e-01\n",
      "   1.97407989e+00 -3.12051667e+00 -2.23701676e+00 -2.40056372e-04\n",
      "   0.00000000e+00 -8.14940143e-01 -1.37171355e+00  4.43384520e-01\n",
      "   9.22397916e-01 -3.94884614e-01 -1.66105209e-01  0.00000000e+00\n",
      "  -1.91446898e-05 -4.17120623e-01 -2.19998115e+00 -3.41662831e+00\n",
      "   1.11030986e+00  1.88419588e+00  2.03296656e+00 -9.94209500e-02\n",
      "  -7.13534248e-05 -3.85484817e-01 -3.14005869e-01 -1.53145046e+00\n",
      "   5.15437204e-01  1.93137173e+00  2.40714631e+00 -6.87493679e-01\n",
      "  -1.60928958e-04  6.58690970e-01  1.61938927e+00  5.10943434e-01\n",
      "   5.34384907e-01 -2.82586012e-02  1.15610708e-01 -1.07682810e+00]\n",
      " [ 0.00000000e+00 -4.83074694e-01 -1.28208395e+00 -3.16000697e+00\n",
      "  -2.15275242e+00 -2.46793390e+00 -1.44475757e+00 -2.54104759e-02\n",
      "  -1.59801512e-02  3.02410455e-01 -1.39953885e+00 -1.74903824e+00\n",
      "  -2.63735922e+00 -1.74380031e+00 -1.30291109e+00  2.05858780e-01\n",
      "  -7.81650923e-06  4.71626542e-02  1.01847750e+00  4.75451480e-01\n",
      "   1.46407280e-01  6.73457097e-01 -5.63833320e-01  4.11410351e-01\n",
      "   5.54114134e-01  5.94449959e-01  2.67809253e+00  2.19746439e-01\n",
      "   2.20205028e-03  9.88198597e-02  2.77532153e+00  2.27129358e-01\n",
      "   0.00000000e+00  1.14010322e+00  9.13265418e-01 -6.24393168e-01\n",
      "   1.36684284e+00  1.83849331e+00  2.64877303e+00  0.00000000e+00\n",
      "   7.99209191e-02  2.95862055e+00 -6.16274960e-02  3.58424472e+00\n",
      "   2.11048777e+00  2.23623731e-01  4.35972980e-01 -1.95637898e-02\n",
      "   3.14679238e-02  1.22933335e+00 -1.24158525e+00  1.62355173e-01\n",
      "   4.12201857e-01 -2.26843191e+00 -2.01245982e+00 -6.02650743e-02\n",
      "  -4.90352613e-03 -2.95982540e-01 -5.26124029e-01 -2.29478728e+00\n",
      "  -1.35564800e+00 -1.95959461e+00 -7.94151740e-01 -2.97814499e-02]\n",
      " [ 0.00000000e+00  1.09568775e+00  2.63699906e+00 -8.11058838e-01\n",
      "   1.26085351e+00  1.97263146e+00  2.34898839e+00 -5.11740939e-01\n",
      "   1.53698000e-02  1.53682264e-02  1.91203452e+00  1.28213660e+00\n",
      "   1.75764118e-01 -1.64923717e+00  2.38100820e-01 -2.17968328e-01\n",
      "  -3.99504376e-04  2.56963926e-01  9.38197412e-01  4.80119232e-02\n",
      "  -3.69429035e+00 -3.07887617e+00 -2.98621463e+00 -1.01652650e-01\n",
      "  -2.20904090e-01  1.37944661e+00  1.61509726e+00 -8.50223378e-01\n",
      "   1.78408222e+00 -2.87928716e-01 -1.83939106e+00 -4.06693746e-03\n",
      "   0.00000000e+00 -6.39209396e-01  1.27109793e+00 -7.66638682e-01\n",
      "  -9.68365912e-01 -1.06022400e-02  6.20550217e-01  0.00000000e+00\n",
      "  -7.60061904e-05 -1.26420806e+00 -1.48491466e+00 -1.39327158e+00\n",
      "  -6.27166341e-01  1.15295029e+00 -1.53144630e-01 -2.17685294e-03\n",
      "  -3.22657791e-05  2.74710947e-02 -1.36786291e-01 -6.83344275e-01\n",
      "  -1.85907622e-01 -3.69687430e-01 -1.08245499e+00 -3.90705406e-02\n",
      "  -6.21563206e-05  6.13275432e-01  2.61527785e+00  1.83760841e+00\n",
      "  -2.62616155e-01 -4.69021390e-01 -1.44260450e+00 -2.00695990e-01]\n",
      " [ 0.00000000e+00 -2.17904168e-01 -1.24897809e+00 -6.75470690e-01\n",
      "  -2.03994269e-01 -1.79664906e+00 -2.30149051e-01 -2.88940554e-04\n",
      "  -1.19107916e-03 -1.24208356e+00 -7.56108770e-01 -1.83278227e-01\n",
      "  -2.11176942e+00 -1.79438378e+00 -1.63738092e-01 -2.27444232e-03\n",
      "  -6.01615877e-06 -9.99247030e-01  8.87550541e-01  6.57747779e-01\n",
      "  -2.12557293e+00 -3.69054637e+00 -3.58072705e-01 -7.36973315e-03\n",
      "  -8.18230770e-03  8.12535924e-01  2.29301228e-01  6.36217952e-01\n",
      "  -2.23040218e-02  6.92293006e-03 -1.36749894e+00 -1.13190441e-02\n",
      "   0.00000000e+00  1.44333321e+00  1.25289127e+00  9.69765779e-01\n",
      "   1.73516743e-01 -1.76943959e-01  7.66867307e-01  0.00000000e+00\n",
      "  -4.77707249e-02 -3.50105519e-01  3.62466857e+00  9.38424927e-01\n",
      "   5.60947078e-01  2.12634692e-01  1.74618957e+00  6.99009492e-02\n",
      "  -9.43604707e-03 -8.44334917e-01  1.11810289e+00  5.85314752e-01\n",
      "  -9.08443871e-01  1.88178565e+00  1.03066775e+00 -1.02807871e+00\n",
      "  -2.64832124e-05 -2.12554731e-01 -1.38810516e+00 -7.33306487e-01\n",
      "   3.50298494e-02  1.83611001e+00  2.99170987e-02 -6.82494925e-01]\n",
      " [ 0.00000000e+00  4.51202028e-01  5.50060901e-01  4.85605596e-01\n",
      "   8.90272026e-01  5.55515041e-01  1.69566700e+00  6.63492797e-01\n",
      "  -1.38482420e-03  6.64122529e-01  5.61181733e-01  7.66461858e-01\n",
      "   2.30941866e+00 -1.06143153e-01  2.49198110e-01  5.78335716e-01\n",
      "  -1.30361600e-04 -1.12378081e+00 -2.40999719e+00 -1.29524487e+00\n",
      "   7.10984752e-02  1.23782282e+00  1.07878751e+00  1.51206484e-01\n",
      "  -4.27062718e-03 -1.34051759e+00 -2.04944253e-01 -2.23868601e+00\n",
      "   4.95816602e-02  1.09962158e+00  1.29361017e+00 -2.40083072e-02\n",
      "   0.00000000e+00  6.40868346e-01  2.21001031e-01 -3.63724246e-01\n",
      "   1.12027675e+00  1.60145832e+00  1.50892405e+00  0.00000000e+00\n",
      "  -4.02567348e-04 -5.83154200e-02  2.30824123e-01  8.93630273e-01\n",
      "   5.91098842e-01  1.00622534e-01 -9.43604597e-02 -5.50048181e-04\n",
      "  -2.60689179e-03 -4.46657234e-01 -3.18595287e-01  6.72314231e-01\n",
      "  -1.94305303e+00 -3.28486165e+00 -9.71796628e-01 -1.17181681e-02\n",
      "  -6.26320022e-03  1.76757537e-02  8.69297039e-02 -1.78396626e+00\n",
      "  -2.15863803e+00 -2.52198065e+00 -7.55080423e-01 -4.31712262e-02]\n",
      " [ 0.00000000e+00 -1.00920740e+00  4.18707964e-01 -7.16487267e-01\n",
      "  -2.96229382e-01 -4.67593961e-02 -1.65255422e+00 -5.00558400e-02\n",
      "   3.00912503e-01 -7.16683110e-01  4.31625928e-01 -5.77134333e-01\n",
      "  -1.19538719e+00  1.70571583e+00  8.74964200e-01 -6.93561729e-02\n",
      "  -2.82658230e-04  7.74714802e-01  1.56616823e+00  1.65711089e-01\n",
      "  -2.66528335e-02  1.53632124e+00  8.16780733e-01 -5.09474070e-02\n",
      "  -8.85830956e-03 -6.11827495e-01 -5.91445652e-01  2.67682777e+00\n",
      "  -6.54723302e-01 -9.56742149e-02 -1.30036795e-01 -5.09799815e-03\n",
      "   0.00000000e+00 -3.78541007e-01 -1.48391013e-01  1.87716858e+00\n",
      "   1.01303910e+00 -2.26096513e+00 -3.04284928e+00  0.00000000e+00\n",
      "  -2.49587818e-04 -9.82616127e-02  1.45224476e+00  1.55838922e+00\n",
      "   1.06208242e+00  9.96752691e-01  2.74489827e-01 -3.29886824e-02\n",
      "  -3.36078135e-02  8.02181112e-01  1.39720961e+00 -2.55790350e+00\n",
      "  -2.39260372e+00  9.01179521e-01  7.95051109e-01 -1.50608067e-01\n",
      "  -8.94822349e-02 -1.94714913e-01 -2.48848690e+00  3.40569704e-01\n",
      "   2.11516151e+00 -2.40201690e-01 -1.21060929e+00 -5.09879921e-01]\n",
      " [ 0.00000000e+00 -1.09702610e+00 -4.15560569e-01  2.28595306e+00\n",
      "   4.59982599e-01 -1.46228709e-01  1.30150849e-01  9.03725094e-02\n",
      "  -5.73065856e-02  1.18067321e+00  1.03384409e+00  1.01866490e+00\n",
      "  -6.91679280e-01  5.57835738e-01  1.17738910e+00 -1.30023040e-01\n",
      "  -8.58739370e-03  3.74724791e-01  7.39110838e-01  8.36036090e-01\n",
      "   1.68781379e+00  4.75444503e+00  3.55698458e-01 -2.96459470e-01\n",
      "  -1.79594436e-04  9.58457362e-01  1.51296905e+00  3.27422624e+00\n",
      "   1.24532790e+00  1.94273004e+00  1.58377468e-01 -1.54165293e-01\n",
      "   0.00000000e+00 -2.07757027e+00 -1.04244647e+00  1.54218359e+00\n",
      "  -1.33578820e+00  3.32666777e-02 -5.17658318e-01  0.00000000e+00\n",
      "  -9.99047141e-06 -2.41095449e-01 -3.73953929e+00 -5.82799754e+00\n",
      "  -2.40323496e+00 -1.54744637e+00 -1.15914376e+00 -1.71047309e-04\n",
      "  -1.15822031e-05  4.34762196e-01 -7.86555585e-01 -1.12260795e+00\n",
      "  -1.07989430e+00 -1.10876689e+00 -1.74540298e-01  1.70074657e-01\n",
      "  -1.02575309e-05 -1.02939151e+00  4.24877584e-01  8.07363850e-01\n",
      "   8.68549459e-01  1.00444358e-01  1.49323740e-01 -8.91575034e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression coefficients:\\n{}\".format(\n",
    "      grid.best_estimator_.named_steps[\"logisticregression\"].coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides this is possible to call the grid-search as any other classifier to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GridSearchCV is 0.964\n"
     ]
    }
   ],
   "source": [
    "accuracy = grid.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.3f}'.format(grid.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to know, we only make the fitting of the grid-search on a single split. However, as previously stated, we might be interested to make an outer cross-validation to estimate the performance of the model and different sample of data and check the potential variation in performance. Since grid-search is an estimator, we can use it directly within the `cross_validate` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.886</td>\n",
       "      <td>9.980e-04</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.643</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.104</td>\n",
       "      <td>1.000e-03</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0    50.886   9.980e-04       0.929        0.986\n",
       "1    51.643   0.000e+00       0.947        0.997\n",
       "2    50.104   1.000e-03       0.924        0.993"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary: my scikit-learn pipeline in less than 10 lines of code (skipping the import statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c58776c0f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
